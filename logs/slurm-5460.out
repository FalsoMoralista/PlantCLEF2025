INFO:root:called-params config/configs.yaml
INFO:root:loaded params...
INFO:root:{'k_means': {'K': 7806}, 'patches': {'N': [16, 32, 64, 80, 128]}, 'num_workers': 32, 'base_dir': '/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/', 'pretrained_path': 'pretrained_models/vit_base_patch14_reg4_dinov2_lvd142m_pc24_onlyclassifier_then_all/model_best.pth.tar', 'data': {'class_mapping': 'pretrained_models/class_mapping.txt', 'species_mapping': 'pretrained_models/species_id_to_name.txt', 'test_data': '/home/rtcalumby/adam/luciano/PlantCLEF2025/test_dataset/'}}
INFO:root:Running... (rank: 0/4)
INFO:root:Initialized (rank/world-size) 0/4
INFO:timm.models._helpers:Loaded state_dict_ema from checkpoint 'pretrained_models/vit_base_patch14_reg4_dinov2_lvd142m_pc24_onlyclassifier_then_all/model_best.pth.tar'
Test dataset created
Test dataset created
Test dataset created
Test dataset created
INFO:root:Image [1/2105]
INFO:root:Image [2/2105]
INFO:root:Image [3/2105]
INFO:root:Image [4/2105]
INFO:root:Image [5/2105]
INFO:root:Image [6/2105]
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_baseline.py", line 126, in main
    dist.all_gather_object(all_cache_lists, local_cache_list)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2440, in all_gather_object
    coalesced_output_tensor = torch.empty(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 91.55 GiB. GPU 
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_baseline.py", line 126, in main
    dist.all_gather_object(all_cache_lists, local_cache_list)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2440, in all_gather_object
    coalesced_output_tensor = torch.empty(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 91.55 GiB. GPU 
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_baseline.py", line 126, in main
    dist.all_gather_object(all_cache_lists, local_cache_list)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2440, in all_gather_object
    coalesced_output_tensor = torch.empty(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 91.55 GiB. GPU 
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_baseline.py", line 126, in main
    dist.all_gather_object(all_cache_lists, local_cache_list)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2440, in all_gather_object
    coalesced_output_tensor = torch.empty(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 91.55 GiB. GPU 
