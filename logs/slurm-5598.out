INFO:root:called-params config/feature_extraction.yaml
INFO:root:loaded params...
INFO:root:{'num_workers': 64, 'base_dir': '/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/', 'pretrained_path': 'pretrained_models/vit_base_patch14_reg4_dinov2_lvd142m_pc24_onlyclassifier_then_all/model_best.pth.tar', 'data': {'class_mapping': 'pretrained_models/class_mapping.txt', 'species_mapping': 'pretrained_models/species_id_to_name.txt', 'train_data': '/home/rtcalumby/adam/luciano/PlantCLEF2025/images_max_side_800/', 'output_dir': '/home/rtcalumby/adam/luciano/PlantCLEF2025/cached_features/'}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:timm.models._helpers:Loaded state_dict_ema from checkpoint 'pretrained_models/vit_base_patch14_reg4_dinov2_lvd142m_pc24_onlyclassifier_then_all/model_best.pth.tar'
Train dataset created
Train dataset created
Train dataset created
Train dataset created
Train dataset created
Train dataset created
Train dataset created
Train dataset created
INFO:root:Iteration [1/85]
INFO:root:Iteration [2/85]
INFO:root:Iteration [3/85]
INFO:root:Iteration [4/85]
INFO:root:Iteration [5/85]
INFO:root:Iteration [6/85]
INFO:root:Iteration [7/85]
INFO:root:Iteration [8/85]
INFO:root:Iteration [9/85]
INFO:root:Iteration [10/85]
INFO:root:Iteration [11/85]
INFO:root:Iteration [12/85]
INFO:root:Iteration [13/85]
INFO:root:Iteration [14/85]
INFO:root:Iteration [15/85]
INFO:root:Iteration [16/85]
INFO:root:Iteration [17/85]
INFO:root:Iteration [18/85]
INFO:root:Iteration [19/85]
INFO:root:Iteration [20/85]
INFO:root:Iteration [21/85]
INFO:root:Iteration [22/85]
INFO:root:Iteration [23/85]
INFO:root:Iteration [24/85]
INFO:root:Iteration [25/85]
INFO:root:Iteration [26/85]
INFO:root:Iteration [27/85]
INFO:root:Iteration [28/85]
INFO:root:Iteration [29/85]
INFO:root:Iteration [30/85]
INFO:root:Iteration [31/85]
INFO:root:Iteration [32/85]
INFO:root:Iteration [33/85]
INFO:root:Iteration [34/85]
INFO:root:Iteration [35/85]
INFO:root:Iteration [36/85]
INFO:root:Iteration [37/85]
INFO:root:Iteration [38/85]
INFO:root:Iteration [39/85]
INFO:root:Iteration [40/85]
INFO:root:Iteration [41/85]
INFO:root:Iteration [42/85]
INFO:root:Iteration [43/85]
INFO:root:Iteration [44/85]
INFO:root:Iteration [45/85]
INFO:root:Iteration [46/85]
INFO:root:Iteration [47/85]
INFO:root:Iteration [48/85]
INFO:root:Iteration [49/85]
INFO:root:Iteration [50/85]
INFO:root:Iteration [51/85]
INFO:root:Iteration [52/85]
INFO:root:Iteration [53/85]
INFO:root:Iteration [54/85]
INFO:root:Iteration [55/85]
INFO:root:Iteration [56/85]
INFO:root:Iteration [57/85]
INFO:root:Iteration [58/85]
INFO:root:Iteration [59/85]
INFO:root:Iteration [60/85]
INFO:root:Iteration [61/85]
INFO:root:Iteration [62/85]
INFO:root:Iteration [63/85]
INFO:root:Iteration [64/85]
INFO:root:Iteration [65/85]
INFO:root:Iteration [66/85]
INFO:root:Iteration [67/85]
INFO:root:Iteration [68/85]
INFO:root:Iteration [69/85]
INFO:root:Iteration [70/85]
INFO:root:Iteration [71/85]
INFO:root:Iteration [72/85]
INFO:root:Iteration [73/85]
INFO:root:Iteration [74/85]
INFO:root:Iteration [75/85]
INFO:root:Iteration [76/85]
INFO:root:Iteration [77/85]
INFO:root:Iteration [78/85]
INFO:root:Iteration [79/85]
INFO:root:Iteration [80/85]
INFO:root:Iteration [81/85]
INFO:root:Iteration [82/85]
INFO:root:Iteration [83/85]
INFO:root:Iteration [84/85]
INFO:root:Iteration [85/85]
INFO:root:Iteration [86/85]
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main_feature_extraction.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_feature_extraction.py", line 98, in main
    dist.barrier()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3683, in barrier
    work = default_pg.barrier(opts=opts)
RuntimeError: ProcessGroupWrapper: Monitored Barrier encountered error running collective: CollectiveFingerPrint(SequenceNumber=0OpType=BARRIER). Error: 
[/opt/conda/conda-bld/pytorch_1712608885084/work/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.65.16.200]:16036
[rank1]:[E ProcessGroupGloo.cpp:144] Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
[rank3]:[E ProcessGroupGloo.cpp:144] Rank 3 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main_feature_extraction.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_feature_extraction.py", line 98, in main
    dist.barrier()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3683, in barrier
    work = default_pg.barrier(opts=opts)
RuntimeError: Rank 1 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[/opt/conda/conda-bld/pytorch_1712608885084/work/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.65.16.200]:50327
[rank6]:[E ProcessGroupGloo.cpp:144] Rank 6 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main_feature_extraction.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_feature_extraction.py", line 98, in main
    dist.barrier()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3683, in barrier
    work = default_pg.barrier(opts=opts)
RuntimeError: Rank 3 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[/opt/conda/conda-bld/pytorch_1712608885084/work/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.65.16.200]:24466
[rank7]:[E ProcessGroupGloo.cpp:144] Rank 7 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main_feature_extraction.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_feature_extraction.py", line 98, in main
    dist.barrier()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3683, in barrier
    work = default_pg.barrier(opts=opts)
RuntimeError: Rank 6 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[/opt/conda/conda-bld/pytorch_1712608885084/work/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.65.16.200]:24466
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/main_feature_extraction.py", line 44, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/PlantCLEF2025/PlantCLEF2025/engine_feature_extraction.py", line 98, in main
    dist.barrier()
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3683, in barrier
    work = default_pg.barrier(opts=opts)
RuntimeError: Rank 7 successfully reached monitoredBarrier, but received errors while waiting for send/recv from rank 0. Please check rank 0 logs for faulty rank.
 Original exception: 
[/opt/conda/conda-bld/pytorch_1712608885084/work/third_party/gloo/gloo/transport/tcp/pair.cc:534] Connection closed by peer [10.65.16.200]:24466
terminate called after throwing an instance of 'c10::DistNetworkError'
  what():  Connection reset by peer
Exception raised from recvBytes at /opt/conda/conda-bld/pytorch_1712608885084/work/torch/csrc/distributed/c10d/Utils.hpp:672 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff732e6c897 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x57c69fe (0x7ff78c1dd9fe in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::check(std::vector<std::string, std::allocator<std::string> > const&) + 0x2d8 (0x7ff78c1d9538 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x34d (0x7ff73413a6fd in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7ff7946d7b65 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/../../../.././libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7ff79d588609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7ff79d353353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistNetworkError'
  what():  Connection reset by peer
Exception raised from recvBytes at /opt/conda/conda-bld/pytorch_1712608885084/work/torch/csrc/distributed/c10d/Utils.hpp:672 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f5d3554a897 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x57c69fe (0x7f5d8e8bb9fe in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::check(std::vector<std::string, std::allocator<std::string> > const&) + 0x2d8 (0x7f5d8e8b7538 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x34d (0x7f5d368186fd in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7f5d96db5b65 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/../../../.././libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7f5d9fc66609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7f5d9fa31353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistNetworkError'
  what():  Connection reset by peer
Exception raised from recvBytes at /opt/conda/conda-bld/pytorch_1712608885084/work/torch/csrc/distributed/c10d/Utils.hpp:672 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fe222604897 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x57c69fe (0x7fe27b9759fe in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::check(std::vector<std::string, std::allocator<std::string> > const&) + 0x2d8 (0x7fe27b971538 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x34d (0x7fe2238d26fd in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7fe283e6fb65 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/../../../.././libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7fe28cd20609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7fe28caeb353 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistNetworkError'
  what():  Connection reset by peer
Exception raised from recvBytes at /opt/conda/conda-bld/pytorch_1712608885084/work/torch/csrc/distributed/c10d/Utils.hpp:672 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fdebcb00897 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x57c69fe (0x7fdf15e719fe in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::check(std::vector<std::string, std::allocator<std::string> > const&) + 0x2d8 (0x7fdf15e6d538 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x34d (0x7fdebddce6fd in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd3b65 (0x7fdf1e36bb65 in /home/rtcalumby/miniconda3/envs/fgdcc/lib/python3.9/site-packages/torch/lib/../../../.././libstdc++.so.6)
frame #5: <unknown function> + 0x8609 (0x7fdf2721c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #6: clone + 0x43 (0x7fdf26fe7353 in /lib/x86_64-linux-gnu/libc.so.6)

